{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da034e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "original_data = pd.read_csv('D:/Fairness_project/final_accepted_rejected_df.csv', index_col=0)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c27c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original_data.copy()\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data.sort_values(by='date', inplace=True)\n",
    "data['year'] = [x.year for x in data['date']]\n",
    "data.drop(data[data['year']<2018].index, axis=0, inplace=True)\n",
    "data.drop(['region', 'date', 'year'], axis=1, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding for employment length\n",
    "\n",
    "emp_map = {10: 'experienced', 9: 'experienced', \n",
    "           8: 'experienced', \n",
    "           7: 'experienced', 6: 'experienced', \n",
    "           5: 'experienced', 4:'Junior',\n",
    "          3: 'Junior', 2: 'Junior', 1: 'Junior', \n",
    "           0: 'Junior'}\n",
    "\n",
    "data['Employment Length'] = data['Employment Length'].map(emp_map)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding for purpose\n",
    "\n",
    "purpose_map = {'other': 'Personal', 'credit_card': 'Debt', 'debt_consolidation': 'Debt'}\n",
    "\n",
    "data['title'] = data['title'].replace(purpose_map)\n",
    "\n",
    "data['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing data\n",
    "\n",
    "data['loan_status'] = np.where(data['loan_status']== 1, 'Accepted', 'Rejected')\n",
    "\n",
    "x = data.drop('loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "x_resampled, y_resampled = rus.fit_resample(x, y)\n",
    "\n",
    "print(x_resampled.shape)\n",
    "print(y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98888602",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train and test split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_resampled,y_resampled, test_size=0.005, stratify=y_resampled)\n",
    "train = pd.concat([xtrain, ytrain], axis=1)\n",
    "test = pd.concat([xtest, ytest], axis=1)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## openai API setting\n",
    "\n",
    "# load key\n",
    "openai.api_key = ''\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def single_request(request: str) -> str:\n",
    "    # call openAI chat completion API\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": request}],\n",
    "        temperature=0\n",
    "    )\n",
    "    reply_msg = completion.choices[0].message.content\n",
    "    return reply_msg\n",
    "\n",
    "def batch_requests(requests: List[str]) -> List[str]:\n",
    "    reply_list = []\n",
    "    for request in tqdm(requests):\n",
    "        reply_list.append(single_request(request))\n",
    "    return reply_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a8397",
   "metadata": {},
   "source": [
    "## Create prompt without example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_without_examples = \"Your task is to determine if a person would be rejected on the requested loan according to the input features.Return 'Rejected' if you think the applicant would be rejected otherwise return 'Accepted'.\\n\\\n",
    "I emphasize that the possible outputs are only 'Rejected' and 'Accepted'. \\n\\\n",
    "A description of the input attributes is in the following quotes:\\n\\\n",
    "\\\"x1: A variable that shows the amount of money requested by the applicant.\\n\\\n",
    "x2: A variable that shows title of the request that represents the purpose of the requested loan. The possible values of this variable are 'Debt' and 'Personal'. 'Debt' refers to the loans asked for debt issues such as credit card. 'Personal' represents loans asked for personal purposes such as education\\n\\\n",
    "x3: a variable that shows the ratio of the borrower’s total monthly debt to the borrower’s self-reported monthly income\\n\\\n",
    "x4: a variable that shows for how many years the applicant has worked. Two possible values of this variable are 'Experienced' and 'Junior'.  \\\" \\n\\\n",
    "<Person Attributes>: *?*\\n\\\n",
    "<Answer>: \"\n",
    "\n",
    "task_requests_without_examples = []\n",
    "\n",
    "for index, row in xtest.iterrows():\n",
    "    sample = \"\"\n",
    "    for i, col in enumerate(xtest.columns):\n",
    "        if col != \"status\":\n",
    "            sample += f\"{col}: {row[col]}, \"\n",
    "    \n",
    "    request = prompt_without_examples.replace(\"*?*\", sample)\n",
    "    task_requests_without_examples.append(request)\n",
    "    \n",
    "print(task_requests_without_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38932f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPT model without examples\n",
    "\n",
    "start_time = time.time()\n",
    "task_response_without_examples = batch_requests(task_requests_without_examples)\n",
    "print(f\"--- {len(task_response_without_examples)} requests in {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_without_examples = test.copy()\n",
    "output_df_without_examples['gpt_label'] = task_response_without_examples\n",
    "\n",
    "output_df_without_examples.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(output_df_without_examples['loan_status'], output_df_without_examples['gpt_label']).ravel()\n",
    "\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b19a6",
   "metadata": {},
   "source": [
    "## Prepare examples for the informed GPT model (using a prompt including examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = train.groupby(['loan_status','title', 'Employment Length'], group_keys=False).apply(lambda x: x.sample(6))\n",
    "examples.reset_index(drop=True, inplace=True)\n",
    "examples.rename(columns={'Loan Amount': 'x1', 'title': 'x2', 'dti': 'x3', 'Employment Length': 'x4'}, inplace=True)\n",
    "examples_x = examples.drop('loan_status', axis=1)\n",
    "examples_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_examples = \"Your task is to determine if a person would be rejected on the requested loan according to the input features.Return 'Rejected' if you think the applicant would be rejected otherwise return 'Accepted'.\\n\\\n",
    "I emphasize that the possible outputs are only 'Rejected' and 'Accepted'. \\n\\\n",
    "Here are some examples in the next triple quotes:\\n\\\n",
    "\"\n",
    "\n",
    "# Generate 48 example lines\n",
    "for i in range(48):\n",
    "    prompt_with_examples += f\"\\\"\\\"\\\"{i + 1}. *<EXAMPLE_{i}>*\\\"\\\"\\\"\\n\"\n",
    "\n",
    "prompt_with_examples += \"A description of the input attributes is in the following quotes:\\n\\\n",
    "\\\"x1: A variable that shows the amount of money requested by the applicant.\\n\\\n",
    "x2: A variable that shows title of the request that represents the purpose of the requested loan. The possible values of this variable are 'Debt' and 'Personal'. 'Debt' refers to the loans asked for debt issues such as credit card. 'Personal' represents loans asked for personal purposes such as education\\n\\\n",
    "x3: a variable that shows the ratio of the borrower’s total monthly debt to the borrower’s self-reported monthly income\\n\\\n",
    "x4: a variable that shows for how many years the applicant has worked. Two possible values of this variable are 'Experienced' and 'Junior'.  \\\" \\n\\\n",
    "<Person Attributes>: *?*\\n\\\n",
    "<Answer>: \"\n",
    "\n",
    "print(prompt_with_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_example_list = []\n",
    "\n",
    "for i in range(len(examples)):\n",
    "    task_example_list.append(pd.DataFrame(examples.iloc[i,:]).T)\n",
    "    \n",
    "task_example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = prompt_with_examples\n",
    "question = \"\"\n",
    "\n",
    "counter = 0\n",
    "for example in task_example_list:\n",
    "    for index, row in examples.iterrows():\n",
    "        sample = \"<Inputs>: \"\n",
    "        question_str = question\n",
    "        answer_str = \"<Answer>: \"\n",
    "        for i, col in enumerate(examples.columns):\n",
    "            if col != \"loan_status\":\n",
    "                sample += f\"{col}: {row[col]}, \"\n",
    "            else:\n",
    "                answer_str += f\"{row[col]}\"\n",
    "        sample = sample.strip()[:-1] + \"\\n\" + question_str + answer_str\n",
    "        task_prompt = task_prompt.replace(f\"*<EXAMPLE_{counter}>*\", sample)\n",
    "        counter += 1\n",
    "print(task_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "task_requests_with_examples = []\n",
    "\n",
    "for index, row in xtest.iterrows():\n",
    "    sample = \"\"\n",
    "    for i, col in enumerate(xtest.columns):\n",
    "        if col != \"status\":\n",
    "            sample += f\"{col}: {row[col]}, \"\n",
    "    \n",
    "    request = task_prompt.replace(\"*?*\", sample)\n",
    "    task_requests_with_examples.append(request)\n",
    "    \n",
    "print(task_requests_with_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "task_response_with_examples = batch_requests(task_requests_with_examples)\n",
    "print(f\"--- {len(task_response_with_examples)} requests in {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_with_examples = test.copy()\n",
    "output_df_with_examples['gpt_label'] = task_response_with_examples\n",
    "\n",
    "output_df_with_examples.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb74a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_with_examples['loan_status'] = np.where(output_df_with_examples['loan_status']== 'Accepted', 1, 0)\n",
    "output_df_with_examples['gpt_label'] = np.where(output_df_with_examples['gpt_label']== 'Accepted', 1, 0)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(output_df_with_examples['loan_status'], output_df_with_examples['gpt_label']).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d303bbe",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categorical_vars = train[['title', 'Employment Length']]\n",
    "test_categorical_vars = test[['title', 'Employment Length']]\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(train_categorical_vars)\n",
    "col_names = encoder.get_feature_names()\n",
    "encoded_train_cat = pd.DataFrame(encoder.transform(train_categorical_vars).toarray(), columns=col_names)\n",
    "encoded_test_cat = pd.DataFrame(encoder.transform(test_categorical_vars).toarray(), columns=col_names)\n",
    "\n",
    "encoded_train = pd.concat([encoded_train_cat,train[['Loan Amount', 'dti']].reset_index(drop=True)], axis=1)\n",
    "encoded_test = pd.concat([encoded_test_cat,test[['Loan Amount', 'dti']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "encoded_ytest = np.where(ytest=='Accepted', 1,0)\n",
    "encoded_ytrain = np.where(ytrain=='Accepted',1,0)\n",
    "\n",
    "lr = LogisticRegression(random_state=0).fit(encoded_train, encoded_ytrain)\n",
    "\n",
    "lr_response_without_examples= lr.predict(encoded_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(encoded_ytest, lr_response_without_examples).ravel()\n",
    "\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f95019",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfcc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_without_examples, fp_without_examples, fn_without_examples, tp_without_examples = confusion_matrix(output_df_without_examples['loan_status'], output_df_without_examples['gpt_label']).ravel()\n",
    "\n",
    "tn_with_examples, fp_with_examples, fn_with_examples, tp_with_examples = confusion_matrix(output_df_with_examples['loan_status'], output_df_with_examples['gpt_label']).ravel()\n",
    "\n",
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(encoded_ytest, lr_response_without_examples).ravel()\n",
    "\n",
    "\n",
    "print('TPR GPT without examples', tp_without_examples/(tp_without_examples+fn_without_examples))\n",
    "print('TPR GPT with examples', tp_with_examples/(tp_with_examples+fn_with_examples))\n",
    "print('TPR Logistic Regression', tp_lr/(tp_lr+fn_lr))\n",
    "\n",
    "print('***********************************************')\n",
    "\n",
    "print('AUC GPT without examples', roc_auc_score(output_df_without_examples['loan_status'], output_df_without_examples['gpt_label']))\n",
    "print('AUC GPT with examples', roc_auc_score(output_df_with_examples['loan_status'], output_df_with_examples['gpt_label']))\n",
    "print('AUC Logistic Regression', roc_auc_score(encoded_ytest, lr_response_without_examples))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
